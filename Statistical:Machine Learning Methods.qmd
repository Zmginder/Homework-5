---
title: "Statistical/Machine Learning Methods"
author: "Zach Ginder"
format: pdf
editor: visual
---

## Task 1: Conceptual Questions

-   Question 1: What is the purpose of using cross-validation when fitting a random forest model?

    -   The purpose of using cross-validation when fitting a random forest model is that it allows us to get a better sense of how well each random forest model performs on unseen data. We want to first tune the tree to determine the number of parameters that will be randomly utilized for each split of the tree model. By staying within the training data set to do this and using cross validation, it allows us to leave the test set untouched and leave that for comparison to other model types and/or a final model test. The more often we utilize the test set we run the risk of over fitting to our data, which cross validation helps prevent.

-   Question 2: Describe the bagged tree algorithm.

    -   A bagged tree algorithm is a type of ensemble tree method. First you split the data set into a training and test set. In order to tune the model paramteres we will use k-fold cross validation within the training data set. For each tuning parameter value we perform B bootstrap resamples within each of the k-folds, fitting a tree to each resample, and aggregating the predictions within each fold. For each tuning parameter value we determing the average prediction accuracy or some other model metric to determine the optimal tuning parameters. The best tuning parameters are then utilized to fit a bagged tree utilizing just the training data set. We then can compare our tunned bagged tree model to other models based on prediction on the test data set and utilizing some sort of metric.

-   Question 3: What is meant by a general linear model?

    -   A general linear model allows for more flexibility than standard linear regression by allowing the errors of the response variable to be non-normal. One example of its utilization is when fitting logistic regression models with the logit link function, which allows us to model a response variable that is binary.

-   Question 4: When fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?

    -   By adding an interaction term it allows for the effect of one variable to depend on the value of another. An interaction term normally effects the slope term of another variable whereas the slope of one term depends on the value of the other term.

-   Question 5: Why do we split our data into a training and test set?

    -   We split our data into a training and test set because if we want our model to do well for prediction this means we want it to predict well for observations it has yet to see. By fitting our model to the training set, we can then use the test set to make predictions and judge the effectiveness of our model with our specified metric.

## Task 2: Data Prep

### Packages and Data

```{r}
#| warning: false
#| message: false
#Library these packages
library(tidyverse)
library(tidymodels)
library(caret)
library(yardstick)

#Read in heart.csv as tibble
heart<-read_csv("heart.csv")
```

### Question 1

```{r}
#Run and report summary()
summary(heart)
```

a.) What type of variable (in R) is Heart Disease? Categorical or Quantitative?

-   Heart Disease is currently quantitative in this tibble.

b.) Does this make sense? Why or why not.

-   This does not make sense as the HeartDisease variable is a binary variable (0 or 1) indicating whether heart disease is present or not. Therefore, the variable HeartDisease should be a factor variable.

### Question 2

```{r}
#Update the Heart tibble
new_heart<-heart|>
  mutate(HeartDiseaseIndicator=as.factor(HeartDisease))|>
  select(-ST_Slope,-HeartDisease)
```

## Task 3: EDA

### Question 1

```{r}
#Create scatterplot for MaxHR vs Age with color being the HeartDiseaseIndicator
plot(x=new_heart$MaxHR,y=new_heart$Age,xlab="Max Heart Rate",ylab="Age")

#Add colored points based on the heart disease indicator variable
points(x=new_heart[new_heart$HeartDiseaseIndicator==0,]$MaxHR,
       y=new_heart[new_heart$HeartDiseaseIndicator==0,]$Age,col="#1A85FF")
points(x=new_heart[new_heart$HeartDiseaseIndicator==1,]$MaxHR,
       y=new_heart[new_heart$HeartDiseaseIndicator==1,]$Age,col="#D41159")

#Add linear regression lines for MaxHR vs Age for each level of the
#HeartDiseaseIndicator variable
abline(lm(Age~MaxHR,data=new_heart[new_heart$HeartDiseaseIndicator==0,]),
          col="#1A85FF")
abline(lm(Age~MaxHR,data=new_heart[new_heart$HeartDiseaseIndicator==1,]),
          col="#D41159")

#Add a legend
legend("topright",legend=c("No Heart Disease", "Heart Disease"),
       fill=c("#1A85FF","#D41159"),cex=.75)

#Add a title
title("Exploring the Heart Disease Data")
```

### Question 2

Based on the scatter plot we would say that an interaction model would be appropriate. We determine this by looking at the slopes of the lines for heart disease and no heart disease. Since the lines for heart disease and no heart disease are not parallel it suggests that the effects of max heart rate on age is dependent on heart disease status. This suggests that an interaction model is more appropriate than an additive model.

## Task 4: Testing and Training

```{r}
#Set seed for reproducibility
set.seed(101)

#Split dataset into training and test sets
heart_split<-initial_split(new_heart,prop=0.8)
train<-training(heart_split)
test<-testing(heart_split)
```

## Task 5: OLS and LASSO

### Question 1

```{r}
#Fit an OLS model
ols_mlr<-lm(Age~MaxHR*HeartDiseaseIndicator,data=new_heart)
summary(ols_mlr)
```

### Question 2

```{r}
#Calculate test RMSE
sqrt(mean((test$Age-predict(ols_mlr,newdata = test))^2))
```

### Question 3

```{r}
#Create folds
heart_CV_folds<-vfold_cv(train,10)

#Create a LASSO recipe
LASSO_recipe<-recipe(Age~MaxHR+HeartDiseaseIndicator,data=train)|>
  step_normalize(MaxHR)|>
  step_dummy(HeartDiseaseIndicator)|>
  step_interact(~MaxHR:starts_with("HeartDiseaseIndicator"))
LASSO_recipe
```

### Question 4

```{r}
#Set spec
LASSO_spec <- linear_reg(penalty = tune(), mixture = 1) |>
  set_engine("glmnet")
#Create workflow
LASSO_wkf <- workflow() |>
  add_recipe(LASSO_recipe) |>
  add_model(LASSO_spec)

#Create tuning grid for LASSO
LASSO_grid <- LASSO_wkf |>
  tune_grid(resamples = heart_CV_folds,
            grid = grid_regular(penalty(), levels = 200)) 

#Final tuning parameter with lowest rmse
lowest_rmse <- LASSO_grid |>
  select_best(metric = "rmse")

#fit it to the entire training set to see the model fit
LASSO_final <- LASSO_wkf |>
  finalize_workflow(lowest_rmse) |>
  fit(train)
tidy(LASSO_final)

```

### Question 5
